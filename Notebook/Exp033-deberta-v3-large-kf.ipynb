{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1651947396719,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"jbiWL2b6FFSO","outputId":"74ab1cad-1fa1-453a-fba8-6ad021d92d89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat May  7 18:16:35 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCMyKjb3FcTI"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"kuruton\"\n","\n","    NAME = \"USP-\" + \"Exp033-deberta-v3-large-kf\"\n","    MODEL_PATH = \"microsoft/deberta-v3-large\"\n","    DATASET_PATH = [\n","        \"yasufuminakama/cpc-data\"\n","    ]\n","\n","    COMPETITION = \"us-patent-phrase-to-phrase-matching\"\n","    COLAB_PATH = \"/content/drive/Shareddrives/USPatent\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 4\n","    trn_fold = [0, 1, 2, 3]\n","    batch_size = 32\n","    n_epochs = 10\n","    max_len = 256\n","\n","    weight_decay = 2e-5\n","    beta = (0.9, 0.98)\n","    lr = 2e-5\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    num_eval = 1\n","    WEB_HOOK_URL = \"https://hooks.slack.com/services/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\"\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eQq96GVpF4dy","outputId":"7e3c9e78-a31a-41a6-e47f-89ff4a4c8902"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# ========================================\n","# Library\n","# ========================================\n","import os\n","import gc\n","import re\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import scipy \n","import itertools\n","from pathlib import Path\n","from glob import glob\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold\n",")\n","from sklearn.metrics import (\n","    accuracy_score, \n","    f1_score,\n","    roc_auc_score,\n",")\n","\n","from google.colab import drive\n","if not os.path.isdir('/content/drive'):\n","    drive.mount('/content/drive') "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pm9K5LTw78z_","outputId":"234148a0-6bf1-42da-c3c1-4a123f980f26"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:41tcmalloc: large alloc 1147494400 bytes == 0x650b6000 @  0x7f1fa3054615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 881.9 MB 19 kB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n","\u001b[?25h"]}],"source":["# torch downgrade\n","! pip install -q torch==1.10.0\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"I7IosBZDF5xl"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install -q torch==1.10.0\n","        ! pip install -q transformers\n","        ! pip install -q sentencepiece\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NaOKiiVuGKyx"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","# collatte\n","def collatte(inputs, labels=None):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    if not labels is None:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        labels =  labels[:,:mask_len]\n","        return inputs, labels, mask_len\n","                \n","    else:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        return inputs, mask_len\n","\n","# =====================\n","# CPC Data\n","# =====================\n","def get_cpc_texts(cfg):\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir(os.path.join(cfg.DATASET, 'cpc-data/CPCSchemeXML202105')):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(os.path.join(cfg.DATASET, f'cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt')) as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    for key, val in results.items():\n","        results[key] = val.lower()\n","    return results\n","\n","\n","def get_optimizer_params(model, lr, weight_decay=0.0):\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    layer_num = len(model.backbone.encoder.layer)\n","    layer1_num = layer_num // 3\n","    layer2_num = layer_num // 3\n","    layer3_num = layer_num - (layer1_num + layer2_num)\n","    group1 = ['layer.' + str(i) + '.' for i in range(layer1_num)]\n","    group2 = ['layer.' + str(i) + '.' for i in range(layer1_num, layer1_num + layer2_num)]\n","    group3 = ['layer.' + str(i) + '.' for i in range(layer1_num + layer2_num, layer1_num + layer2_num + layer3_num)]\n","    group_all = group1 + group2 + group3\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.backbone.named_parameters() if (not any(nd in n for nd in no_decay)) and (not any(nd in n for nd in group2)) and (not any(nd in n for nd in group3))] ,\n","          'lr': lr * 0.25, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay) and (not any(nd in n for nd in group2)) and (not any(nd in n for nd in group3))],\n","          'lr': lr * 0.25, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n","          'lr': lr * 0.2, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in group2) and (not any(nd in n for nd in no_decay))],\n","        'lr': lr * 0.5, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in group2) and any(nd in n for nd in no_decay)],\n","        'lr': lr * 0.5, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in group3) and (not any(nd in n for nd in no_decay))],\n","        'lr': lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in group3) and any(nd in n for nd in no_decay)],\n","        'lr': lr, 'weight_decay': 0.0}\n","    ]\n","    return optimizer_grouped_parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Z3Ol0XFxGR7v"},"outputs":[],"source":["class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.texts[index])\n","        label = torch.tensor(self.labels[index], dtype=torch.float)\n","        return inputs, label\n","    \n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(\n","            text,\n","            add_special_tokens=True,\n","            max_length=cfg.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False\n","        )\n","        for k, v in inputs.items():\n","            inputs[k] = torch.tensor(v, dtype=torch.long)\n","        return inputs\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, criterion):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.criterion = criterion\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH, \n","            config=self.config\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 1),\n","        )\n","\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","\n","    def forward(self, inputs, labels=None):\n","        outputs = self.backbone(**inputs)[\"last_hidden_state\"]\n","        attention_mask = inputs['attention_mask']\n","        outputs[attention_mask[:,:outputs.shape[1]] == 0] = float('-inf')\n","        outputs, _ = outputs.max(1)  # max pooling\n","        logits1 = self.fc(self.dropout1(outputs)).flatten()\n","        logits2 = self.fc(self.dropout2(outputs)).flatten()\n","        logits4 = self.fc(self.dropout3(outputs)).flatten()\n","        logits3 = self.fc(self.dropout4(outputs)).flatten()\n","        logits5 = self.fc(self.dropout5(outputs)).flatten()\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        \n","        loss = 0\n","        if labels is not None:\n","            loss1 = self.criterion(logits1, labels,)\n","            loss2 = self.criterion(logits2, labels)\n","            loss3 = self.criterion(logits3, labels)\n","            loss4 = self.criterion(logits4, labels)\n","            loss5 = self.criterion(logits5, labels)\n","            loss = (loss1 + loss2 + loss3 + loss4 + loss5) / 5\n","\n","        return logits, loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FQYTH7VBR7j4"},"outputs":[],"source":["# evaluating\n","def evaluating(cfg, valid_loader, model, criterion, valid_df, fold, best_val_preds, best_val_score):\n","    # evaluating\n","    val_preds = []\n","    val_losses = []\n","    val_nums = []\n","    model.eval()\n","    with torch.no_grad():\n","        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","            for (inputs, labels) in pbar:\n","                for k, v in inputs.items():\n","                    inputs[k] = v.to(cfg.device)\n","                labels = labels.to(cfg.device)\n","                with autocast():\n","                    output, loss = model(inputs, labels)\n","                output = output.sigmoid().detach().cpu().numpy()\n","                val_preds.append(output)\n","                val_losses.append(loss.item() * len(labels))\n","                val_nums.append(len(labels))\n","                pbar.set_postfix({\n","                    'val_loss': loss.item()\n","                })\n","\n","    val_preds = np.concatenate(val_preds)\n","    val_loss = sum(val_losses) / sum(val_nums)\n","    corr_score = np.corrcoef(val_preds, valid_df['score'])[0, 1]\n","\n","    val_log = {\n","        'val_loss': val_loss,\n","        'score': corr_score,\n","    }\n","    display(val_log)\n","\n","    if best_val_score < corr_score:\n","        print(\"save model weight\")\n","        best_val_preds = val_preds\n","        best_val_score = corr_score\n","        torch.save(\n","            model.state_dict(), \n","            os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","        )\n","    return best_val_preds, best_val_score\n","\n","\n","def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros(len(train), dtype=np.float32)\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # reverse anchor_target\n","        # rev_train_df = train_df.copy()\n","        # rev_train_df[['anchor', 'target']] = rev_train_df[['target', 'anchor']].to_numpy()\n","        # train_df = pd.concat([train_df, rev_train_df]).reset_index(drop=True)\n","\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False\n","        )\n","        # model-training\n","        criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","        best_val_preds = None\n","        best_val_score = -1\n","\n","        # model\n","        model = CustomModel(cfg, criterion)\n","        model = model.to(cfg.device)\n","\n","\n","        # optimizer, scheduler\n","        # param_optimizer = list(model.named_parameters())\n","        # no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        # optimizer_grouped_parameters = [\n","        #     {\n","        #         'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","        #         'weight_decay': cfg.weight_decay\n","        #     },\n","        #     {\n","        #         'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","        #         'weight_decay': 0.0\n","        #     }\n","        # ]\n","\n","        optimizer_grouped_parameters = get_optimizer_params(\n","            model,\n","            lr=cfg.lr,\n","            weight_decay=cfg.weight_decay\n","        )\n","\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","        num_eval_step = len(train_loader) // cfg.num_eval + cfg.num_eval\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            model.train() \n","            val_losses_batch = []\n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    inputs, max_len = collatte(inputs)\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        output, loss = model(inputs, labels)\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","\n","                    if cfg.gradient_accumulation_steps > 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","                    if step % num_eval_step == 0 and step != 0:\n","                        tmp_num_eval = step // num_eval_step\n","                        print(f'fold: {fold}, epoch: {epoch}, num_eval: {tmp_num_eval}')\n","                        best_val_preds, best_val_score = evaluating(\n","                            cfg, valid_loader,\n","                            model,\n","                            criterion,\n","                            valid_df,\n","                            fold,\n","                            best_val_preds,\n","                            best_val_score\n","                        )\n","                        model.train() \n","            \n","            print(f'fold: {fold}, epoch: {epoch}, last')\n","            best_val_preds, best_val_score = evaluating(\n","                cfg, valid_loader,\n","                model,\n","                criterion,\n","                valid_df,\n","                fold,\n","                best_val_preds,\n","                best_val_score\n","            )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    corr_score = np.corrcoef(oof_pred, train['score'])[0, 1]\n","    print('CV:', round(corr_score, 5))\n","    return corr_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["887cdfa8d52f4bd5bf768a153828778c","fc3175611bb343c095851a6628b6a8c0","23ebe4b88bbf457ba4c11be930850ad8","66771b8b68ec47ffa5130eaa0f477959","b748a75862584211ac3bd826b30e81a3","95e779850f0f49ad92b1c0989c99ac9f","0ff5d42013bf4429a66130b515d74dcb","db6b53497a5345ebb028b3acac003a61","52f7e5811abc48a6b9e306027b7814c4","7f4df19a3bd040e68c24f834e4165789","7e7fdfe627004049bf5ff3c9e2c4afb1","42ec4d0326774f5daec4732fdb8c4702","220d0100c34b4664a88d8fafe62671df","52085dad8b6f422cba4de37715435f34","d84b0b589a5b44a7b519c543023f7569","79176b72c0a6452badfcd3a77034281b","a6bfe078a7564dd1844f3be2b0ba538d","d6a2e4e87349459083aab310ad3a2d18","82893277c778402b9bce36abbae5d779","afcd9e38b0214ce0bb4c4be734a79993","927e3ebe23424e289e103789e1f874c5","454cfb3d8156421a8ac9aad0a5821f63","e87ebc51880a48b2a9329e343299664b","cee6db696f92453d86c293e6ba7f068c","dc328de40e2c48ec9f4f5af487fb1e51","d223e167a79a4d3a9274a3932ab4b2f3","9898160216654260842524d06ce363e6","7ea2f30ba42444b8b703b9e0742a4165","ff0bea53081740e49d2745a9c45fa21b","0cfb6c1b1112499388817aa6c10a0cf5","6a3551d590054b2ab8b519ad7c48b4b2","292979ef060640229902b220c47eb95b","0b515a526f9f4c6292c6cc56807c3a08","00f0c400f41e4cb5b94b6cffecce4ad8","00beaec48e65401a86756950d89fdf1a","a966f3aec059453ab272e981f33923e5","4bb48d7cd6084549a0d4633dd2beacac","02dfac0543eb482fa702a25ec8fee1bf","360393e38e7d4b7b858377b66de20095","a32473618b204f808a8cb914f1ca3f88","c8c60dda9d924f73a9c08085bfd68775","709df5f0cb6d434683561279722d6e25","7c2392eb1bb3419e9a9469e0325e6ae4","d8e6cdeb309c43549893717d0d6b7cd8","627f6f2e706b423b8411aad2859d6375","7ded7145087749e59e3103db64295658","dd6a8032d4fd4c6caed207f9974ecf36","77e1958e32f54db98ccff3fe8ce2a6f0","209fd0285eae4eeab10a4bc739b3ce32","87dd451407c04a608df0492c56077325","8f5057d312f64cf28a01073b51687320","138773d848c8426ebfbcca1ece71db50","4081ee9597064db09666892668d8eb08","f41a8bf90ede4705bc1b119196289fb4","63343dec4b12409baed821097115539d","64dffc7dd4294a9783a0040680d46ff0","d23e5d9aa5d74b4d841381b2e12b115f","31905c62c2834f2c8e1931d057c3a24b","80f436b79f3d4c2f86a8ca28ae42dd75","560f1e5d47e542e0b5b4ca5ce2ee5e47","4e2d356055d241f68aab9ffee4d60911","117611ed57a445c1bfa3f6d4c8c97eec","de5271d3dc1f497eb2f335def8d4c160","199d6f56358244138b868fa39941a010","5373a342ec6644698026fa4eb23b9a0e","1e9607925777457d81c37cdffa05ca28","70073e00e5e540e39d0e69e4b381c5bf","6788af02f52540eca51ae876f05219b7","70ea6b711091468280ab96a4fa9bc0fe","308e6adc305f4fe0bc23f9f2b820c8f3","0fa09a0fd3f84043b322b3415d16ffe2","31112ed0dbbb4bb9af8bc07f2fef70e9","187a590d1b36447da3448b9db1b9e5f5","49f84234627a4959b4eabe964deb871f","c75a76d1dbfe439ea137b97d8059b7f2","e1ffc40041db4465bb854e4aa075715c","69878572b3d641e0b7d04c62683d5078","7bb691cc9adb4005867225594f65ef5e","9a6c1b5fbf0244af8d87103f78a1821f","b5b525213d624e1da880c2ef3ecabb3f","c170be42c6c049038998dea296414c33","f0b8495b413147078ce47f308a6a121b","e850034918744b6b88adf7a18e710fc1","0c789a5535a74789b8df235361b4d9e8"]},"id":"HNUHCnVxJyhW","outputId":"8c7d1c5d-291b-4dc0-8e86-1f91eb3da99d"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","\u001b[K     |████████████████████████████████| 4.0 MB 4.3 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 51.6 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 46.1 MB/s \n","\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s \n","\u001b[K     |████████████████████████████████| 880 kB 63.5 MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n","\u001b[?25h"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"887cdfa8d52f4bd5bf768a153828778c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc3175611bb343c095851a6628b6a8c0","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23ebe4b88bbf457ba4c11be930850ad8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["[SEP]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66771b8b68ec47ffa5130eaa0f477959","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b748a75862584211ac3bd826b30e81a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95e779850f0f49ad92b1c0989c99ac9f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8433498477869583, 'val_loss': 0.536315293976293}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ff5d42013bf4429a66130b515d74dcb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db6b53497a5345ebb028b3acac003a61","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8529064369396722, 'val_loss': 0.5313119579464841}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52f7e5811abc48a6b9e306027b7814c4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f4df19a3bd040e68c24f834e4165789","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8541952162231313, 'val_loss': 0.538666190125464}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e7fdfe627004049bf5ff3c9e2c4afb1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42ec4d0326774f5daec4732fdb8c4702","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.859575630164894, 'val_loss': 0.5378582453156449}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"220d0100c34b4664a88d8fafe62671df","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52085dad8b6f422cba4de37715435f34","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8606161442126714, 'val_loss': 0.534024859581983}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d84b0b589a5b44a7b519c543023f7569","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79176b72c0a6452badfcd3a77034281b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8615593039787891, 'val_loss': 0.537164278355381}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6bfe078a7564dd1844f3be2b0ba538d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6a2e4e87349459083aab310ad3a2d18","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8601208517648683, 'val_loss': 0.5444387291846196}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82893277c778402b9bce36abbae5d779","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afcd9e38b0214ce0bb4c4be734a79993","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8623473327547588, 'val_loss': 0.5438311727394175}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"927e3ebe23424e289e103789e1f874c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"454cfb3d8156421a8ac9aad0a5821f63","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8619924841170589, 'val_loss': 0.5496912421149007}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e87ebc51880a48b2a9329e343299664b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cee6db696f92453d86c293e6ba7f068c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8618019694017846, 'val_loss': 0.5477338809593948}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc328de40e2c48ec9f4f5af487fb1e51","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d223e167a79a4d3a9274a3932ab4b2f3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.829997700591257, 'val_loss': 0.5532039791234467}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9898160216654260842524d06ce363e6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ea2f30ba42444b8b703b9e0742a4165","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8397676396921514, 'val_loss': 0.5557803301061813}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff0bea53081740e49d2745a9c45fa21b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cfb6c1b1112499388817aa6c10a0cf5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8539689759106454, 'val_loss': 0.5313250498503388}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a3551d590054b2ab8b519ad7c48b4b2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"292979ef060640229902b220c47eb95b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8590312253610796, 'val_loss': 0.5343889112233541}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b515a526f9f4c6292c6cc56807c3a08","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00f0c400f41e4cb5b94b6cffecce4ad8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8609148591671304, 'val_loss': 0.5363052535943489}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00beaec48e65401a86756950d89fdf1a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a966f3aec059453ab272e981f33923e5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8564145887479783, 'val_loss': 0.5455220040652177}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bb48d7cd6084549a0d4633dd2beacac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02dfac0543eb482fa702a25ec8fee1bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.85558423812244, 'val_loss': 0.5588709049238973}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"360393e38e7d4b7b858377b66de20095","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a32473618b204f808a8cb914f1ca3f88","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8606720143543977, 'val_loss': 0.5472717827925898}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8c60dda9d924f73a9c08085bfd68775","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"709df5f0cb6d434683561279722d6e25","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8586539270677522, 'val_loss': 0.5548022006668786}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c2392eb1bb3419e9a9469e0325e6ae4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8e6cdeb309c43549893717d0d6b7cd8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8584565716843632, 'val_loss': 0.5516326847986893}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"627f6f2e706b423b8411aad2859d6375","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ded7145087749e59e3103db64295658","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8313655770078713, 'val_loss': 0.5444919815396081}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd6a8032d4fd4c6caed207f9974ecf36","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77e1958e32f54db98ccff3fe8ce2a6f0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8396611963434105, 'val_loss': 0.540831712822455}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"209fd0285eae4eeab10a4bc739b3ce32","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87dd451407c04a608df0492c56077325","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8525956710084184, 'val_loss': 0.5359193336338713}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f5057d312f64cf28a01073b51687320","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"138773d848c8426ebfbcca1ece71db50","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8483598877424835, 'val_loss': 0.5493753117070592}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4081ee9597064db09666892668d8eb08","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f41a8bf90ede4705bc1b119196289fb4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.855053772665772, 'val_loss': 0.5532934003217254}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63343dec4b12409baed821097115539d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64dffc7dd4294a9783a0040680d46ff0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8603185769813703, 'val_loss': 0.5442524592221163}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d23e5d9aa5d74b4d841381b2e12b115f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31905c62c2834f2c8e1931d057c3a24b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8556742449192708, 'val_loss': 0.5542538769937027}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80f436b79f3d4c2f86a8ca28ae42dd75","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"560f1e5d47e542e0b5b4ca5ce2ee5e47","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8559771795101199, 'val_loss': 0.5550014246422671}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e2d356055d241f68aab9ffee4d60911","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"117611ed57a445c1bfa3f6d4c8c97eec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8562859951598082, 'val_loss': 0.552784193108599}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de5271d3dc1f497eb2f335def8d4c160","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"199d6f56358244138b868fa39941a010","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8553143132919034, 'val_loss': 0.5575252131663752}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5373a342ec6644698026fa4eb23b9a0e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e9607925777457d81c37cdffa05ca28","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8222997904211126, 'val_loss': 0.5490021972338289}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70073e00e5e540e39d0e69e4b381c5bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6788af02f52540eca51ae876f05219b7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8484792614799312, 'val_loss': 0.5396752006117517}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70ea6b711091468280ab96a4fa9bc0fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"308e6adc305f4fe0bc23f9f2b820c8f3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8573726329280182, 'val_loss': 0.5404863817947009}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fa09a0fd3f84043b322b3415d16ffe2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31112ed0dbbb4bb9af8bc07f2fef70e9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8567354059149663, 'val_loss': 0.5422595652160637}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"187a590d1b36447da3448b9db1b9e5f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49f84234627a4959b4eabe964deb871f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8542967321880718, 'val_loss': 0.5603915320059322}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c75a76d1dbfe439ea137b97d8059b7f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1ffc40041db4465bb854e4aa075715c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.856244958725641, 'val_loss': 0.5575838917231032}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69878572b3d641e0b7d04c62683d5078","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bb691cc9adb4005867225594f65ef5e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8630121984928026, 'val_loss': 0.5500017210275726}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a6c1b5fbf0244af8d87103f78a1821f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5b525213d624e1da880c2ef3ecabb3f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8600611468474318, 'val_loss': 0.5597743123253335}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c170be42c6c049038998dea296414c33","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0b8495b413147078ce47f308a6a121b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8595140915104447, 'val_loss': 0.5618931393883264}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e850034918744b6b88adf7a18e710fc1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c789a5535a74789b8df235361b4d9e8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8603375378664714, 'val_loss': 0.561654354578624}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CV: 0.86155\n","Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.47G/6.47G [05:18<00:00, 21.8MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (6GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:05<00:00, 1.97kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 510k/510k [00:04<00:00, 122kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (510KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","print(cfg.tokenizer.sep_token)\n","\n","cpc_texts = get_cpc_texts(cfg)\n","torch.save(cpc_texts, os.path.join(cfg.EXP_PREDS, \"cpc_texts.pth\"))\n","train['context_text'] = train['context'].map(cpc_texts)\n","train['text'] = train['anchor'] + cfg.tokenizer.sep_token + train['target'] + cfg.tokenizer.sep_token + train['context_text']\n","\n","# cfg.folds = get_groupkfold(train, 'score', 'anchor', cfg.num_fold)\n","cfg.folds = get_kfold(train, cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","\n","score = training(cfg, train)\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9a8-TXYHmKc7"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"kuruton-Exp033-deberta-v3-large-kf.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}