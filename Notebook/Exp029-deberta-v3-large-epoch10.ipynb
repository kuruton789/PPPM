{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1651860058091,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"jbiWL2b6FFSO","outputId":"fa81ac2f-0ca7-496c-9098-5f1c875fdb95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri May  6 18:00:56 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651860058092,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"eCMyKjb3FcTI"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"kuruton\"\n","\n","    NAME = \"USP-\" + \"Exp029-deberta-v3-large-dropout\"\n","    MODEL_PATH = \"microsoft/deberta-v3-large\"\n","    DATASET_PATH = [\n","        \"yasufuminakama/cpc-data\"\n","    ]\n","\n","    COMPETITION = \"us-patent-phrase-to-phrase-matching\"\n","    COLAB_PATH = \"/content/drive/Shareddrives/USPatent\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 4\n","    trn_fold = [0, 1, 2, 3]\n","    batch_size = 32\n","    n_epochs = 10\n","    max_len = 256\n","\n","    fc_dropout = 0.1\n","    weight_decay = 2e-5\n","    beta = (0.9, 0.98)\n","    lr = 2e-5\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    num_eval = 1\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3515,"status":"ok","timestamp":1651860061602,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"eQq96GVpF4dy"},"outputs":[],"source":["# ========================================\n","# Library\n","# ========================================\n","import os\n","import gc\n","import re\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import scipy \n","import itertools\n","from pathlib import Path\n","from glob import glob\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold\n",")\n","from sklearn.metrics import (\n","    accuracy_score, \n","    f1_score,\n","    roc_auc_score,\n",")\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651860061603,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"I7IosBZDF5xl"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install -q transformers\n","        ! pip install -q sentencepiece\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n","\n","\n","def setting_deberta_tokenizer(cfg):\n","    # The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n","    # This must be done before importing transformers\n","    # https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizer\n","\n","    if cfg.COLAB:\n","        ! pip install --quiet transformers\n","        ! pip install --quiet sentencepiece\n","        transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","    else:\n","        transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n","\n","    input_dir = Path(f\"{cfg.DATASET}/deberta-v2-3-fast-tokenizer\")\n","    convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","    conversion_path = transformers_path/convert_file.name\n","\n","    if conversion_path.exists():\n","        conversion_path.unlink()\n","\n","    shutil.copy(convert_file, transformers_path)\n","    deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","    for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n","        if str(filename).startswith(\"deberta\"):\n","            filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n","        else:\n","            filepath = deberta_v2_path/filename\n","        if filepath.exists():\n","            filepath.unlink()\n","\n","        shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1651860061604,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"NaOKiiVuGKyx"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","# collatte\n","def collatte(inputs, labels=None):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    if not labels is None:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        labels =  labels[:,:mask_len]\n","        return inputs, labels, mask_len\n","                \n","    else:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        return inputs, mask_len\n","\n","# =====================\n","# CPC Data\n","# =====================\n","def get_cpc_texts(cfg):\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir(os.path.join(cfg.DATASET, 'cpc-data/CPCSchemeXML202105')):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(os.path.join(cfg.DATASET, f'cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt')) as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    for key, val in results.items():\n","        results[key] = val.lower()\n","    return results"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651860061605,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"Z3Ol0XFxGR7v"},"outputs":[],"source":["class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.texts[index])\n","        label = torch.tensor(self.labels[index], dtype=torch.float)\n","        return inputs, label\n","    \n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(\n","            text,\n","            add_special_tokens=True,\n","            max_length=cfg.max_len,\n","            padding=\"max_length\",\n","            return_offsets_mapping=False\n","        )\n","        for k, v in inputs.items():\n","            inputs[k] = torch.tensor(v, dtype=torch.long)\n","        return inputs\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, criterion):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.criterion = criterion\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH, \n","            config=self.config\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 1),\n","        )\n","\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","\n","    def forward(self, inputs, labels=None):\n","        outputs = self.backbone(**inputs)[\"last_hidden_state\"]\n","        outputs = outputs[:, 0, :]\n","        logits1 = self.fc(self.dropout1(outputs)).flatten()\n","        logits2 = self.fc(self.dropout2(outputs)).flatten()\n","        logits4 = self.fc(self.dropout3(outputs)).flatten()\n","        logits3 = self.fc(self.dropout4(outputs)).flatten()\n","        logits5 = self.fc(self.dropout5(outputs)).flatten()\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        \n","        loss = 0\n","        if labels is not None:\n","            loss1 = self.criterion(logits1, labels,)\n","            loss2 = self.criterion(logits2, labels)\n","            loss3 = self.criterion(logits3, labels)\n","            loss4 = self.criterion(logits4, labels)\n","            loss5 = self.criterion(logits5, labels)\n","            loss = (loss1 + loss2 + loss3 + loss4 + loss5) / 5\n","\n","        return logits, loss"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651860061605,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"FQYTH7VBR7j4"},"outputs":[],"source":["# evaluating\n","def evaluating(cfg, valid_loader, model, criterion, valid_df, fold, best_val_preds, best_val_score):\n","    # evaluating\n","    val_preds = []\n","    val_losses = []\n","    val_nums = []\n","    model.eval()\n","    with torch.no_grad():\n","        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","            for (inputs, labels) in pbar:\n","                for k, v in inputs.items():\n","                    inputs[k] = v.to(cfg.device)\n","                labels = labels.to(cfg.device)\n","                with autocast():\n","                    output, loss = model(inputs, labels)\n","                output = output.sigmoid().detach().cpu().numpy()\n","                val_preds.append(output)\n","                val_losses.append(loss.item() * len(labels))\n","                val_nums.append(len(labels))\n","                pbar.set_postfix({\n","                    'val_loss': loss.item()\n","                })\n","\n","    val_preds = np.concatenate(val_preds)\n","    val_loss = sum(val_losses) / sum(val_nums)\n","    corr_score = np.corrcoef(val_preds, valid_df['score'])[0, 1]\n","\n","    val_log = {\n","        'val_loss': val_loss,\n","        'score': corr_score,\n","    }\n","    display(val_log)\n","\n","    if best_val_score \u003c corr_score:\n","        print(\"save model weight\")\n","        best_val_preds = val_preds\n","        best_val_score = corr_score\n","        torch.save(\n","            model.state_dict(), \n","            os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","        )\n","    return best_val_preds, best_val_score\n","\n","\n","def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros(len(train), dtype=np.float32)\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # reverse anchor_target\n","        # rev_train_df = train_df.copy()\n","        # rev_train_df[['anchor', 'target']] = rev_train_df[['target', 'anchor']].to_numpy()\n","        # train_df = pd.concat([train_df, rev_train_df]).reset_index(drop=True)\n","\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False\n","        )\n","        # model-training\n","        criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","        best_val_preds = None\n","        best_val_score = -1\n","\n","        # model\n","        model = CustomModel(cfg, criterion)\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {\n","                'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                'weight_decay': cfg.weight_decay\n","            },\n","            {\n","                'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                'weight_decay': 0.0\n","            }\n","        ]\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","        num_eval_step = len(train_loader) // cfg.num_eval + cfg.num_eval\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            model.train() \n","            val_losses_batch = []\n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    inputs, max_len = collatte(inputs)\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        output, loss = model(inputs, labels)\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","\n","                    if cfg.gradient_accumulation_steps \u003e 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","                    if step % num_eval_step == 0 and step != 0:\n","                        tmp_num_eval = step // num_eval_step\n","                        print(f'fold: {fold}, epoch: {epoch}, num_eval: {tmp_num_eval}')\n","                        best_val_preds, best_val_score = evaluating(\n","                            cfg, valid_loader,\n","                            model,\n","                            criterion,\n","                            valid_df,\n","                            fold,\n","                            best_val_preds,\n","                            best_val_score\n","                        )\n","                        model.train() \n","            \n","            print(f'fold: {fold}, epoch: {epoch}, last')\n","            best_val_preds, best_val_score = evaluating(\n","                cfg, valid_loader,\n","                model,\n","                criterion,\n","                valid_df,\n","                fold,\n","                best_val_preds,\n","                best_val_score\n","            )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    corr_score = np.corrcoef(oof_pred, train['score'])[0, 1]\n","    print('CV:', round(corr_score, 5))\n","    return corr_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":402},"id":"HNUHCnVxJyhW"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Mounted at /content/drive\n","\u001b[K     |████████████████████████████████| 4.0 MB 15.8 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 23.4 MB/s \n","\u001b[K     |████████████████████████████████| 880 kB 54.2 MB/s \n","\u001b[K     |████████████████████████████████| 77 kB 7.4 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 62.7 MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.2 MB 15.4 MB/s \n","\u001b[?25h"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0773e164264b4efb81e08e36c7edf9ed","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0adf72e9fad4a2f8ee404613eccb3eb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"deb0dd62420642baa42bc400f5c1c68e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3d4898381b2409e8069aa2b17270da8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6a33e849cb64264847691e4bec20fb5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7f086970ee546ff8fc19419cdd7412f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8124705661193206, 'val_loss': 0.5530728210298518}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb0fd29469df4cf0a43e2d93c5e4ff4d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4bb955cf4fd4957858656ae3f3be2f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8067958288012014, 'val_loss': 0.5587743543025524}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9627f547a98498487d728fae05d1bea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2cb2c4a7036a4b50b2aad83d4e483ef3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8196392474673361, 'val_loss': 0.550072896332186}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aeace7de6a5e4f349fc47987014c204a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3498b6f561634952a0feafa97813431c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8149209424639704, 'val_loss': 0.5613668297862442}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06bd67dab5154495ac8a6521367b3cf3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7822a9c1fe69440f82e20790eeb15bdf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8159680963849474, 'val_loss': 0.558999364951133}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fe5c273a70f47a9a9e5ca79fc2474db","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0bfbad1bfac40d7ad065951c8f74830","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8195069511180725, 'val_loss': 0.561835659620257}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d546b1568d8457fa004ba89599fa436","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8d3e960b59f4757b1415317dc112d60","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8171094246986422, 'val_loss': 0.5738974775265596}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c0be01d9a384b3390297dfaeb9a5e48","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71ebc7e5c10f41eab5c6050700a801e7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8145407018828652, 'val_loss': 0.565964810304284}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2269e5e734e2433499fc03905ef0ff09","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d3fa16d67c24ecab2dc41604d4374c1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.817531311285385, 'val_loss': 0.5621269251127909}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"628f642b1a7e4c95a838982986f5b1d5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13f991a9f11b438fb87203acbca63bfb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.814969233025177, 'val_loss': 0.5777155462685535}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"004717ff8fb94372865f988ecb6c1b99","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2526e2cd5788467d839c1ce346a1ae15","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6551452193848003}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3efa5e3bb4384f7781715e71719ce886","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"993859f5d11a46aeb0f88d05cbbee0e4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6606333277078542}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5c11aa0914c4504beb2f329fbe7e21d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3985747012d74c0e91ab739eab6beaa5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.0054366234091365595, 'val_loss': 0.6542663552385067}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a19ae155ee0347848d76a02ba2547bb3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e76e9ec4fee41a7b04eef924eeed4fd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6546928019057138}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"846d95d0d50840fba003d3c6a79ed61f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f56268c51d94474d842eee03e0e3808d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': -0.004497301745657961, 'val_loss': 0.6549129255326805}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ced198dcb69474c863fc904bb868979","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a4be2d2afa645ab919eb4989c6ecc81","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6543045960959961}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a423d6f1d3fc49b4ac8866a55ef257e8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"203055891cff4354b8302d42835c4a1e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.042583733161684595, 'val_loss': 0.6542670440192703}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9447f6fcdd2b4cd1818f62f20e5917a2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"172825f625464a2182ab8b5a6f8b7bbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6548131312762313}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"293043d2b07d4bca8da2fa1bce3362af","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98d089547b4e453e91ae086d006f1c6f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6542769492025515}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"177287045a8f4c729511c91ebfa0f608","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f84482dab73540529164e3e10fcba7c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6542967237723347}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30846161b9cf471ea9fb18639cf2bbba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4305ebb0a55c464aa3686ffd59772a30","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': -0.016781991851621304, 'val_loss': 0.6543937746070148}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0aeb1e33b266459497180746ac78a1b0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"207371a7d85e40418c408e4c55b51fea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6551616700837214}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54d0b441873b4c7f92ab957b0e625fef","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f200f118b66f4d81a02bb0b76a60888f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': -0.004544753359362467, 'val_loss': 0.6546820339782115}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed0ee26695824d76b08d1a6f34749674","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c49c1f9badd4a2ba25daa8cad406b25","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': -0.0014321928477883988, 'val_loss': 0.6541870748246283}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0315f58013914c8daf0ac2b562872cc4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24ad15b9f6414ac9862f5d59d48fe94b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.011072753426045053, 'val_loss': 0.6541869568050783}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80f3788c30cc43d8a0d04b54a23b49dc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3ad3241aa4b41a2b21d94eb30b87c6d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6542664284793973}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55910bcc77664b3c9ad1fac9ba5fc422","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a4fe7c76ed14ba0bb3c11a455eccdbb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6546663988784469}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4c0e9c872194b2c8add8ab4ad7e998c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb2fc4ab771f4107b7bc4bff6ce9e59d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6541776816085075}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d5b272a7b12446aa08b655559faf464","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06030b1fa46d41c3ad30ad005a595bb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.654176359938592}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b182f53ac9243669d733bdac4d9879a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b8c9e36eb2e4255bd5a69d83105b570","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': nan, 'val_loss': 0.6543014769387836}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebe0f983096644a9bf4c7649773f0c27","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65e38d0323c145ad84a06f4ea16542be","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8175947096223334, 'val_loss': 0.5472783881939668}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47b042b0d81a43fda81c2ae0a4c2b13a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d5c770ed81446eb88dac4d873e1ed04","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.81922388848224, 'val_loss': 0.5491275778070932}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de8b09cc5bec4b45aa17abe7cf57821a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d1601ea6069410fa53d7c54c3178232","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8235508740823849, 'val_loss': 0.5556006781964429}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"563de271891d4886a0a1faa6c342ce9b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"092bc61cfc9c4f598ae3e7d37a128b1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8235806254513848, 'val_loss': 0.563099425295043}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fce6f07a929c43f6b77de63d1fc94898","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82fb5cdd3069425fba80b9ec78a72316","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8218820198982587, 'val_loss': 0.5596124438189394}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd578e1bf76643caaefe81bc5fecd570","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 5, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a16abff86b3a47b6bc120a88d975c770","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8214931423671147, 'val_loss': 0.5601209864252412}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"513fa94150ca4b92aa3d4a3152c99976","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 6, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d9d2131813c40718dd69ab5013e4cb8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8225362492004133, 'val_loss': 0.5745043705549907}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:7 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de6582ce4a6b49d7ae47b992e5659645","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 7, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b462427542541b19ddafc1f7ac801a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8218771007414623, 'val_loss': 0.5791334246145735}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:8 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"846fce4dbad649d6af06a8e1caae06f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 8, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62fa8e66c2384ccbad3cc2d2f7da1be2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8209698692881651, 'val_loss': 0.581748374697147}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:9 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"953bb930940742bda402be15396e7dbb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/854 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 9, last\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25e215cf14984574bdf0a57acec2689c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/285 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8212821996135026, 'val_loss': 0.5863212218643359}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CV: 0.58123\n","Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.47G/6.47G [03:03\u003c00:00, 37.9MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (6GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:02\u003c00:00, 3.69kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 510k/510k [00:02\u003c00:00, 178kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (510KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","cfg = setup(Config)\n","setting_deberta_tokenizer(cfg)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n","\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","\n","cpc_texts = get_cpc_texts(cfg)\n","torch.save(cpc_texts, os.path.join(cfg.EXP_PREDS, \"cpc_texts.pth\"))\n","train['context_text'] = train['context'].map(cpc_texts)\n","train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]' + train['context_text']\n","\n","cfg.folds = get_groupkfold(train, 'score', 'anchor', cfg.num_fold)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","\n","score = training(cfg, train)\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9a8-TXYHmKc7"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","name":"kuruton-Exp029-deberta-v3-large-epoch10.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02b0076357264ce9950430184d835e5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f6caff66688476296efa60af64b095e","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b22ab944b3834aac80e819acdb3196ff","value":52}},"05a2fdd4871d4c9a8233b528774bdfa9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e999dc976984dcc80740494b6a6f41b","placeholder":"​","style":"IPY_MODEL_c6be6aa367e14b1aa6a69fce724cce2a","value":" 580/580 [00:00\u0026lt;00:00, 16.2kB/s]"}},"0773e164264b4efb81e08e36c7edf9ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d800c8b6d43641c6ba513653ca6626ec","IPY_MODEL_02b0076357264ce9950430184d835e5a","IPY_MODEL_6ec2aab6d4a54956b1a4c7d8973f91e4"],"layout":"IPY_MODEL_d47ca769640447599ae8b0468dd9a13d"}},"2d70977e5f664ea5a7ea77895241c4ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31990d844be74ffdae44ad6b92ff38c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31e115be460742ad860d69aacfa191d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32a71447d0dd421f8011d4ec45542935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"337a5733ff1749f1bae7c3c6f7c457bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33b36d0c9f0645ec92d5607462cc0957":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"357372e638224f2ca27a2fea343e8e93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33b36d0c9f0645ec92d5607462cc0957","placeholder":"​","style":"IPY_MODEL_72c1366d5dce44ed87be2d09267a18e3","value":"Downloading: 100%"}},"3b4d2a43b3de44f0afb48295059e6fbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d5dbef9fd494817a6450eccb94189e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f5a3ee619664bd89f433253035f6e32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dd8ac999d354c83a475178197104a87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56d0f07696d14a3aa2016c9d0f6c5144":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b4b5630dcb24cc99b17144926cc65ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f6caff66688476296efa60af64b095e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"602b20cb7b59462e97ab344091370b8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e999dc976984dcc80740494b6a6f41b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ec2aab6d4a54956b1a4c7d8973f91e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91fff6c417bc4e008600e8f34e335947","placeholder":"​","style":"IPY_MODEL_3b4d2a43b3de44f0afb48295059e6fbc","value":" 52.0/52.0 [00:00\u0026lt;00:00, 1.41kB/s]"}},"727dadbd4733478a805d01a617908643":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72c1366d5dce44ed87be2d09267a18e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73cd599324364328939d5ff053a50b4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdf51bf3dd74416096468dad385b193e","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31e115be460742ad860d69aacfa191d3","value":580}},"8094d5acb3654dc89339eec5048958e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8105f6faf4f34ff1957b33e0bd313996":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91fff6c417bc4e008600e8f34e335947":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a398649f011542a898c9d2af85e78978":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_727dadbd4733478a805d01a617908643","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32a71447d0dd421f8011d4ec45542935","value":2464616}},"a3e78cfd1c624203abd16e8c6b0fdd91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56d0f07696d14a3aa2016c9d0f6c5144","placeholder":"​","style":"IPY_MODEL_4dd8ac999d354c83a475178197104a87","value":" 2.35M/2.35M [00:00\u0026lt;00:00, 25.6MB/s]"}},"a91ca374ba224af394b68b3067fa791e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adb1ed8a600b4af7907bf0f810ce574b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b22ab944b3834aac80e819acdb3196ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc7c33e775e644deb839f6735df69f2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d4898381b2409e8069aa2b17270da8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e860b617c3ec4f98af5aac9d270cc301","IPY_MODEL_f8f69f2e21a94ccfb6fbc154255643b8","IPY_MODEL_f3c8f3c1fd444a5d9f2113afd7b78705"],"layout":"IPY_MODEL_31990d844be74ffdae44ad6b92ff38c1"}},"c6be6aa367e14b1aa6a69fce724cce2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0adf72e9fad4a2f8ee404613eccb3eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_357372e638224f2ca27a2fea343e8e93","IPY_MODEL_73cd599324364328939d5ff053a50b4a","IPY_MODEL_05a2fdd4871d4c9a8233b528774bdfa9"],"layout":"IPY_MODEL_3f5a3ee619664bd89f433253035f6e32"}},"d47ca769640447599ae8b0468dd9a13d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d800c8b6d43641c6ba513653ca6626ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc7c33e775e644deb839f6735df69f2e","placeholder":"​","style":"IPY_MODEL_602b20cb7b59462e97ab344091370b8e","value":"Downloading: 100%"}},"d88093ebf0a4403cbeee3b1026ff78ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d70977e5f664ea5a7ea77895241c4ed","placeholder":"​","style":"IPY_MODEL_5b4b5630dcb24cc99b17144926cc65ea","value":"Downloading: 100%"}},"deb0dd62420642baa42bc400f5c1c68e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d88093ebf0a4403cbeee3b1026ff78ab","IPY_MODEL_a398649f011542a898c9d2af85e78978","IPY_MODEL_a3e78cfd1c624203abd16e8c6b0fdd91"],"layout":"IPY_MODEL_a91ca374ba224af394b68b3067fa791e"}},"e112600230df4b3d9f409d622e944743":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e860b617c3ec4f98af5aac9d270cc301":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d5dbef9fd494817a6450eccb94189e7","placeholder":"​","style":"IPY_MODEL_8105f6faf4f34ff1957b33e0bd313996","value":"Downloading: 100%"}},"f3c8f3c1fd444a5d9f2113afd7b78705":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_337a5733ff1749f1bae7c3c6f7c457bc","placeholder":"​","style":"IPY_MODEL_e112600230df4b3d9f409d622e944743","value":" 833M/833M [00:15\u0026lt;00:00, 58.0MB/s]"}},"f8f69f2e21a94ccfb6fbc154255643b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8094d5acb3654dc89339eec5048958e7","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adb1ed8a600b4af7907bf0f810ce574b","value":873673253}},"fdf51bf3dd74416096468dad385b193e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}