{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1652965067770,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"jbiWL2b6FFSO","outputId":"96a3c00c-fe91-41f3-c2a0-21ba6828569f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu May 19 12:57:43 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCMyKjb3FcTI"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"kuruton\"\n","\n","    NAME = \"USP-\" + \"MLM002-deberta-v3-base\"\n","    MODEL_PATH = \"microsoft/deberta-v3-base\"\n","    DATASET_PATH = [\n","        'fankaixie/pppm-abstract',\n","        'fankaixie/cpc-description'\n","    ]\n","\n","    COMPETITION = \"us-patent-phrase-to-phrase-matching\"\n","    COLAB_PATH = \"/content/drive/Shareddrives/USPatent\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    train_size = 0.8\n","    batch_size = 2\n","    num_train_epochs = 10\n","    max_len = 512\n","\n","    weight_decay = 2e-5\n","    lr = 2e-5\n","    mlm_probability = 0.15\n","    warmup_ratio = 0.01\n","    gradient_accumulation_steps = 1\n","    lr_scheduler_type = 'cosine'\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30352,"status":"ok","timestamp":1652965098115,"user":{"displayName":"クルトン","userId":"17231302919530674825"},"user_tz":-540},"id":"eQq96GVpF4dy","outputId":"95caafdb-156a-4e64-8331-f491ec0d5d1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# ========================================\n","# Library\n","# ========================================\n","import os\n","import gc\n","import re\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from pathlib import Path\n","from glob import glob\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import (\n","    train_test_split,\n","    KFold,\n","    StratifiedKFold,\n","    GroupKFold,\n","    StratifiedGroupKFold,\n",")\n","from sklearn.metrics import (\n","    accuracy_score, \n","    f1_score,\n","    roc_auc_score,\n",")\n","\n","import torch\n","\n","from google.colab import drive\n","if not os.path.isdir('/content/drive'):\n","    drive.mount('/content/drive') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7IosBZDF5xl"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install -q transformers\n","        ! pip install -q sentencepiece\n","        ! pip install -q datasets\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQYTH7VBR7j4"},"outputs":[],"source":["def get_text(cfg):\n","    df = pd.read_csv(os.path.join(cfg.DATASET, 'cpc-description/CPC_description.csv'))['claim']\n","    df = df[df.notnull()].reset_index(drop=True)\n","    train, test = train_test_split(\n","        df,\n","        train_size=cfg.train_size,\n","        shuffle=True,\n","        random_state=cfg.seed,\n","    )\n","    train, test = train.tolist(), test.tolist()\n","    return train, test\n","\n","def get_dataset(cfg):\n","    train, test = get_text(cfg)\n","    train_path = os.path.join('./', 'train_mlm.json')\n","    valid_path = os.path.join('./', 'valid_mlm.json')\n","\n","    for path, text_list in zip(\n","        [train_path, valid_path],\n","        [train, test]):\n","        with open(str(path), 'w') as f:\n","            for sentence in text_list:\n","                row_json = {'text': sentence}\n","                json.dump(row_json, f)\n","                f.write('\\n')\n","\n","    datasets = load_dataset(\n","        'json',\n","        data_files={\n","            'train': train_path,\n","            'valid': valid_path\n","        },\n","    )\n","    return datasets\n","\n","def main(cfg):\n","    if 'KAGGLE_URL_BASE' in set(os.environ.keys()):\n","        os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","    datasets = get_dataset(cfg)\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","    tokenized_datasets = datasets.map(\n","        lambda x: tokenizer(x['text'],  max_length=cfg.max_len),\n","        batched=True,\n","        num_proc=1,\n","        remove_columns=[\"text\"],\n","        batch_size=cfg.batch_size\n","    )\n","\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm_probability=cfg.mlm_probability,\n","    )\n","\n","    config = AutoConfig.from_pretrained(cfg.MODEL_PATH, output_hidden_states=True)\n","    model = AutoModelForMaskedLM.from_pretrained(cfg.MODEL_PATH, config=config)\n","\n","    training_args = TrainingArguments(\n","        output_dir=os.path.join(cfg.EXP_MODEL, \"mlm\"),\n","        evaluation_strategy=\"epoch\",\n","        learning_rate=cfg.lr,\n","        weight_decay=cfg.weight_decay,\n","        save_strategy='no',\n","        per_device_train_batch_size=cfg.batch_size,\n","        num_train_epochs=cfg.num_train_epochs,\n","        lr_scheduler_type=cfg.lr_scheduler_type,\n","        warmup_ratio=cfg.warmup_ratio,\n","        fp16=True,\n","        logging_steps=500,\n","        gradient_accumulation_steps=cfg.gradient_accumulation_steps\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_datasets[\"train\"],\n","        eval_dataset=tokenized_datasets['valid'],\n","        data_collator=data_collator,\n","        # optimizers=(optimizer, scheduler)\n","    )\n","    trainer.train()\n","    trainer.model.save_pretrained(os.path.join(cfg.EXP_MODEL), 'model')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"HNUHCnVxJyhW"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","\u001b[K     |████████████████████████████████| 4.2 MB 14.7 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 60.5 MB/s \n","\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 57.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 14.3 MB/s \n","\u001b[K     |████████████████████████████████| 342 kB 14.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 67.2 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 76.1 MB/s \n","\u001b[K     |████████████████████████████████| 136 kB 78.4 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 62.0 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 51.5 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 74.0 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h"]},{"name":"stderr","output_type":"stream","text":["Using custom data configuration default-b22b0002c724b9be\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-b22b0002c724b9be/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbd9e20631064ef29256a008e6c23d72","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d59a7ba1f4741648444bbf21c1dbff1","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-b22b0002c724b9be/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ec6464a72f14bf6831aa697d6ba0178","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69b7efeacb114b958a9efb9cda81469f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8144991beec44cd78e640b8c91d77adb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/579 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"205cf915a726431db63914d7eb5848db","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b98611e4dbeb4a59807fb7c2a2615da1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20000 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52c0e96d73344bccaa5c87b1e12ad67f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5000 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa0040b281824ae3a26a08dfacbe5635","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/354M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForMaskedLM: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using amp half precision backend\n","***** Running training *****\n","  Num examples = 40000\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed \u0026 accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 200000\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='200000' max='200000' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [200000/200000 7:19:00, Epoch 10/10]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eEpoch\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1.604000\u003c/td\u003e\n","      \u003ctd\u003e1.414526\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e1.307200\u003c/td\u003e\n","      \u003ctd\u003e1.204905\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1.233400\u003c/td\u003e\n","      \u003ctd\u003e1.110896\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e1.173600\u003c/td\u003e\n","      \u003ctd\u003e1.056832\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e1.070500\u003c/td\u003e\n","      \u003ctd\u003e1.018209\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e1.052600\u003c/td\u003e\n","      \u003ctd\u003e0.980940\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e1.035300\u003c/td\u003e\n","      \u003ctd\u003e0.954795\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e8\u003c/td\u003e\n","      \u003ctd\u003e0.991300\u003c/td\u003e\n","      \u003ctd\u003e0.941625\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e9\u003c/td\u003e\n","      \u003ctd\u003e0.948900\u003c/td\u003e\n","      \u003ctd\u003e0.920191\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e0.978500\u003c/td\u003e\n","      \u003ctd\u003e0.928898\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 10000\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Configuration saved in /content/drive/Shareddrives/USPatent/kuruton/Output/USP-MLM002-deberta-v3-base/model/config.json\n","Model weights saved in /content/drive/Shareddrives/USPatent/kuruton/Output/USP-MLM002-deberta-v3-base/model/pytorch_model.bin\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModel,\n","    AutoTokenizer,\n",")\n","from transformers import (\n","    DataCollatorForLanguageModeling,\n","    AutoModelForMaskedLM,\n","    Trainer,\n",")\n","from transformers import TrainingArguments\n","from transformers.utils import logging\n","from datasets import load_dataset\n","\n","main(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"V2BFmbk4hcMZ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","name":"MLM002-deberta-v3-base.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}